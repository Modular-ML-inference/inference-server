# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: inference_application/code/proto/extended-inference.proto
# Protobuf Python Version: 4.25.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n9inference_application/code/proto/extended-inference.proto\x12\x12\x65xtended_inference\x1a&tensorflow/core/framework/tensor.proto\"\xb5\x01\n\x18\x45xtendedInferenceRequest\x12\n\n\x02id\x18\x01 \x01(\x05\x12\x46\n\x05input\x18\x02 \x03(\x0b\x32\x37.extended_inference.ExtendedInferenceRequest.InputEntry\x1a\x45\n\nInputEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tensorflow.TensorProto:\x02\x38\x01\"\xba\x01\n\x19\x45xtendedInferenceResponse\x12\n\n\x02id\x18\x01 \x01(\x05\x12I\n\x06output\x18\x02 \x03(\x0b\x32\x39.extended_inference.ExtendedInferenceResponse.OutputEntry\x1a\x46\n\x0bOutputEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12&\n\x05value\x18\x02 \x01(\x0b\x32\x17.tensorflow.TensorProto:\x02\x38\x01\x32\x88\x01\n\x18\x45xtendedInferenceService\x12l\n\x07predict\x12,.extended_inference.ExtendedInferenceRequest\x1a-.extended_inference.ExtendedInferenceResponse\"\x00(\x01\x30\x01\x62\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'inference_application.code.proto.extended_inference_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:
  DESCRIPTOR._options = None
  _globals['_EXTENDEDINFERENCEREQUEST_INPUTENTRY']._options = None
  _globals['_EXTENDEDINFERENCEREQUEST_INPUTENTRY']._serialized_options = b'8\001'
  _globals['_EXTENDEDINFERENCERESPONSE_OUTPUTENTRY']._options = None
  _globals['_EXTENDEDINFERENCERESPONSE_OUTPUTENTRY']._serialized_options = b'8\001'
  _globals['_EXTENDEDINFERENCEREQUEST']._serialized_start=122
  _globals['_EXTENDEDINFERENCEREQUEST']._serialized_end=303
  _globals['_EXTENDEDINFERENCEREQUEST_INPUTENTRY']._serialized_start=234
  _globals['_EXTENDEDINFERENCEREQUEST_INPUTENTRY']._serialized_end=303
  _globals['_EXTENDEDINFERENCERESPONSE']._serialized_start=306
  _globals['_EXTENDEDINFERENCERESPONSE']._serialized_end=492
  _globals['_EXTENDEDINFERENCERESPONSE_OUTPUTENTRY']._serialized_start=422
  _globals['_EXTENDEDINFERENCERESPONSE_OUTPUTENTRY']._serialized_end=492
  _globals['_EXTENDEDINFERENCESERVICE']._serialized_start=495
  _globals['_EXTENDEDINFERENCESERVICE']._serialized_end=631
# @@protoc_insertion_point(module_scope)
